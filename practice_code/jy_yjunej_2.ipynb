{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63843100",
   "metadata": {},
   "source": [
    "# 작물 병해 분류 AI 경진대회 Private 2위, Private Score: 0.99848,  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6401dd5",
   "metadata": {},
   "source": [
    "## yjunej팀, 사용모델: SE-ResNeXt101-32x4d, SE-ResNeXt26-32x4d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e19743",
   "metadata": {},
   "source": [
    "## requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de54a9b",
   "metadata": {},
   "source": [
    "### Pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a9391",
   "metadata": {},
   "source": [
    "* pretraining dataset: ImageNet\n",
    "* SE-ResNeXt101-32x4d: ported from  https://cv.gluon.ai/model_zoo/classification.html#resnext, using timm library\n",
    "* SE-ResNeXt26d_32x4d: https://rwightman.github.io/pytorch-image-models/models/resnext/, using timm library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a806f",
   "metadata": {},
   "source": [
    "## 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03f232ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.accelerators import accelerator\n",
    "import torch\n",
    "import torchvision\n",
    "# from pytorch_lightning.plugins import DDPPlugin\n",
    "from pytorch_lightning.strategies import DDPStrategy\n",
    "from pytorch_lightning import seed_everything\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchmetrics import F1Score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision.transforms.transforms import ColorJitter, RandomCrop, RandomHorizontalFlip\n",
    "\n",
    "from config import Config\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import albumentations.pytorch as Ap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ce588a",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e2f6ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              img_path  label description\n",
      "0   ./train\\가구수정\\0.png      0        가구수정\n",
      "1   ./train\\가구수정\\1.png      0        가구수정\n",
      "2  ./train\\가구수정\\10.png      0        가구수정\n",
      "3  ./train\\가구수정\\11.png      0        가구수정\n",
      "4   ./train\\가구수정\\2.png      0        가구수정\n",
      "(3457, 3)\n",
      "(792, 2)\n",
      "18    1405\n",
      "10     595\n",
      "1      307\n",
      "3      210\n",
      "15     162\n",
      "2      145\n",
      "11     142\n",
      "7      130\n",
      "6       99\n",
      "9       57\n",
      "5       54\n",
      "17      51\n",
      "14      27\n",
      "12      22\n",
      "13      17\n",
      "4       14\n",
      "0       12\n",
      "16       5\n",
      "8        3\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data 폴더 상대 경로, ipynb 파일과 같은 depth에 존재하는 'fd_data' 폴더\n",
    "\n",
    "DATA_DIR = './data'\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "print(train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4877255",
   "metadata": {},
   "source": [
    "* Train data가 매우 적고, imblanced class\n",
    "* f1-macro 점수 향상을 위해서는 데이터가 적은 class에서도 좋은 점수를 얻어야합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d254c",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa44aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config & pre-defined function\n",
    "\n",
    "# mixup augmentation을 위한 코드입니다.\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam, weight):\n",
    "    return lam * criterion(pred, y_a, weight=weight) + (1 - lam) * criterion(pred, y_b,weight=weight)\n",
    "\n",
    "class Config:\n",
    "    exp = 'exp_1' # exp_1: 기존 train data만 사용, exp_2: pseudo labeling 추가한 최종 train data 사용\n",
    "    phase = 'train' # train or test\n",
    "    data_dir = './data' \n",
    "    model_name = \"seresnext26d_32x4d\"\n",
    "    max_epochs = 25\n",
    "    fold_num = 5 # k-fold \n",
    "    batch_size = 64 # \n",
    "    num_workers = 0\n",
    "    seed = 41\n",
    "    tta = True # Test Time Augmentation\n",
    "    ckpt = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c57b1f",
   "metadata": {},
   "source": [
    "## Pytorch lightning Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76846ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDDataset(Dataset):\n",
    "    def __init__(self, cfg:Config, df:pd.DataFrame, aug:bool = True):\n",
    "        super(FDDataset, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.aug = aug\n",
    "        # Augmentation\n",
    "        if self.aug:\n",
    "            self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((256,256)),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomAffine(\n",
    "                degrees=(-90,90),\n",
    "                translate=(0.2, 0.2),\n",
    "                scale=(0.8, 1.2), shear=15\n",
    "                ),\n",
    "            ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                transforms.Resize((256,256)),\n",
    "            ]\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.cfg.data_dir, self.df.loc[idx, 'img_path'])\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        img = self.transform(img)\n",
    "        if self.cfg.phase == 'test':\n",
    "            return img, self.df.loc[idx, 'uid']\n",
    "        label = self.df.loc[idx, 'label']\n",
    "        return img, label\n",
    "        \n",
    "class FDDataModule(LightningDataModule):\n",
    "    def __init__(self, cfg:Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.test_df = pd.read_csv(os.path.join(cfg.data_dir, 'test.csv'))\n",
    "        \n",
    "        # exp_1은 train.csv 데이터 사용\n",
    "        if 'exp_1'  in self.cfg.exp:\n",
    "            self.train_df = pd.read_csv(os.path.join(cfg.data_dir, 'train.csv'))\n",
    "            print('Data: train.csv')\n",
    "        # exp 2는 pseudo-labeling data를 추가한 full_train.csv 파일을 load\n",
    "        elif 'exp_2' in self.cfg.exp:\n",
    "            self.train_df = pd.read_csv(os.path.join(cfg.data_dir, 'full_train.csv'))\n",
    "            print('Data: full_train.csv')\n",
    "        self.fold_num = 0\n",
    "        self._split_kfold()\n",
    "\n",
    "    def set_fold_num(self, fold_num):\n",
    "        self.fold_num = fold_num\n",
    "    \n",
    "    # weighted crossentropy loss를 위한 weight 계산 함수\n",
    "    def get_class_weight(self):\n",
    "        return 1 / self.train_df['label'].value_counts().sort_index().values\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage != 'test':\n",
    "            print(f'FOLD NUM:{self.fold_num}')\n",
    "            train_df = self.train_df[\n",
    "                self.train_df[\"kfold\"] != self.fold_num\n",
    "            ].reset_index(drop=True)\n",
    "            val_df = self.train_df[\n",
    "                self.train_df[\"kfold\"] == self.fold_num\n",
    "            ].reset_index(drop=True)\n",
    "\n",
    "            self.train = FDDataset(self.cfg, train_df, aug=True)\n",
    "            self.val = FDDataset(self.cfg, val_df, aug=False)\n",
    "            self.train_fold_df = self.train_df\n",
    "\n",
    "        if stage == 'test':\n",
    "            self.test = FDDataset(self.cfg, self.test_df, aug=False)\n",
    "\n",
    "    # Stratified KFold \n",
    "    def _split_kfold(self):\n",
    "        skf = StratifiedKFold(\n",
    "            n_splits=Config.fold_num, shuffle=True, random_state=Config.seed\n",
    "        )\n",
    "        # (train_idx, val_idx)\n",
    "        for n, (_, val_index) in enumerate(\n",
    "            skf.split(\n",
    "                X=self.train_df,\n",
    "                y=self.train_df['label']\n",
    "            )\n",
    "        ):  # if valid index, record fold num in 'kfold' column\n",
    "            self.train_df.loc[val_index, \"kfold\"] = int(n)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train,\n",
    "            batch_size=self.cfg.batch_size,\n",
    "            num_workers=self.cfg.num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val,\n",
    "            batch_size=self.cfg.batch_size,\n",
    "            num_workers=self.cfg.num_workers,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test,\n",
    "            batch_size=self.cfg.batch_size,\n",
    "            num_workers=self.cfg.num_workers,\n",
    "            shuffle=False,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a94f119",
   "metadata": {},
   "source": [
    "## Pytorch lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89cf99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDModel(nn.Module):\n",
    "    def __init__(self, cfg:Config):\n",
    "        super(FDModel, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.cnn = timm.create_model( # timm ImageNet pre-trained 모델 load\n",
    "            cfg.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes = 7,\n",
    "            in_chans = 3\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        return out\n",
    "\n",
    "class FDModule(LightningModule):\n",
    "    def __init__(self, cfg:Config, class_weight=None):\n",
    "        super().__init__()\n",
    "        self.model = FDModel(cfg)\n",
    "        self.val_metric = F1Score(task='multiclass', num_classes=19, average=\"weighted\")\n",
    "        self.train_metric =  F1Score(task='multiclass', num_classes=19, average=\"weighted\")\n",
    "        self.cfg = cfg\n",
    "        self.lr = 1e-4\n",
    "\n",
    "        self.class_weight = class_weight\n",
    "        \n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "        ## TTA에 사용할 augmentation\n",
    "        self.horizontalflip = transforms.RandomHorizontalFlip(p=1)\n",
    "        self.verticalflip = transforms.RandomVerticalFlip(p=1)\n",
    "        self.rotation_left = transforms.RandomRotation(degrees=(-90,-90))\n",
    "        self.rotation_right = transforms.RandomRotation(degrees=(90,90))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        if batch_idx % 4 == 0: # 4 step 주기로 mixup 사용\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(x, y)\n",
    "            logits = self(mixed_x)\n",
    "            loss = mixup_criterion(F.cross_entropy, logits, y_a, y_b, lam, torch.Tensor(self.class_weight).cuda())\n",
    "            self.log_dict({'mixup_loss':loss})\n",
    "            return loss\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y.long(), weight= torch.Tensor(self.class_weight).cuda())\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        micro_acc = accuracy(preds, y)\n",
    "        f1_score = self.train_metric(preds, y)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"train_loss\": loss,\n",
    "                \"train_acc\": micro_acc,\n",
    "                \"train_f1_macro\": f1_score\n",
    "            },\n",
    "            prog_bar=True,\n",
    "            sync_dist=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True\n",
    "\n",
    "        )\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y.long(), weight= torch.Tensor(self.class_weight).cuda())\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        micro_acc = accuracy(preds, y)\n",
    "\n",
    "        f1_score = self.val_metric(preds, y)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"val_loss\": loss,\n",
    "                \"val_acc\": micro_acc,\n",
    "                \"val_f1_macro\": f1_score                \n",
    "            },\n",
    "            prog_bar=True,\n",
    "            sync_dist=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True\n",
    "        )\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        if self.cfg.tta:\n",
    "            return self.tta(batch,batch_idx)\n",
    "        x, uid = batch\n",
    "        logits = self(x)\n",
    "        prob = self.softmax(logits)\n",
    "        preds = prob\n",
    "\n",
    "        return preds, uid\n",
    "\n",
    "    def tta(self, batch, batch_idx):\n",
    "        x, uid = batch\n",
    "        _normal = self.softmax(self(x))\n",
    "        _h_flip = self.softmax(self(self.horizontalflip(x)))\n",
    "        _v_flip = self.softmax(self(self.verticalflip(x)))\n",
    "        _l_rotate = self.softmax(self(self.rotation_left(x)))\n",
    "        _r_rotate = self.softmax(self(self.rotation_right(x)))\n",
    "        preds = (_normal + _h_flip + _v_flip + _l_rotate + _r_rotate) / 5\n",
    "        return preds, uid  \n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        results = self.all_gather(outputs)\n",
    "        \n",
    "        # class 별 confidence 저장하는 dataframe\n",
    "        df = pd.DataFrame(range(20000,24750),columns=['uid'])\n",
    "        df['prob_0'] = -100.0\n",
    "        df['prob_1'] = -100.0\n",
    "        df['prob_2'] = -100.0\n",
    "        df['prob_3'] = -100.0\n",
    "        df['prob_4'] = -100.0\n",
    "        df['prob_5'] = -100.0\n",
    "        df['prob_6'] = -100.0\n",
    "        \n",
    "        df = df.set_index('uid')\n",
    "        for p, u in results:\n",
    "            prob = p.reshape(-1,7).cpu().numpy()\n",
    "            u = u.reshape(-1).cpu().numpy()\n",
    "            for pp, uu in zip(prob,u):\n",
    "                df.loc[uu] = pp\n",
    "        df.to_csv(f'result_{self.cfg.exp}.csv')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if 'exp_1' in self.cfg.exp:\n",
    "            optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "            print('optimizer: AdamW')\n",
    "            if 'exp_1_1' in self.cfg.exp:\n",
    "                scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=200, T_mult=1)\n",
    "                print('scheduler: CosineAnnealing')\n",
    "            elif 'exp_1_2' in self.cfg.exp:\n",
    "                scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=40, verbose=True)\n",
    "                print('scheduler: ReduceLROnPlateau')\n",
    "                return (\n",
    "                {\n",
    "                \"optimizer\":optimizer,\n",
    "                \"lr_scheduler\": {\"scheduler\":scheduler, \"monitor\":\"val_loss\", \"interval\":\"epoch\"},\n",
    "                },\n",
    "                )\n",
    "        elif 'exp_2_2' in self.cfg.exp:\n",
    "            optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "            print('optimizer: AdamW')\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100, T_mult=1)\n",
    "            print('scheduler: CosineAnnealing')\n",
    "            return (\n",
    "            {\n",
    "                \"optimizer\":optimizer,\n",
    "                \"lr_scheduler\": {\"scheduler\":scheduler, \"monitor\":\"val_loss\", \"interval\":\"epoch\"},\n",
    "            },\n",
    "            )\n",
    "        \n",
    "        \n",
    "        elif 'exp_2_1' in self.cfg.exp:\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "            print('optimizer: Adam')\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100, T_mult=1)\n",
    "            print('scheduler: CosineAnnealing')\n",
    "            return (\n",
    "            {\n",
    "                \"optimizer\":optimizer,\n",
    "                \"lr_scheduler\": {\"scheduler\":scheduler, \"monitor\":\"val_loss\", \"interval\":\"epoch\"},\n",
    "            },\n",
    "            )\n",
    "        \n",
    "        return [optimizer], [scheduler]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a10cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.accelerators import accelerator\n",
    "\n",
    "# from pytorch_lightning.plugins import DDPPlugin\n",
    "from pytorch_lightning.strategies import DDPStrategy\n",
    "from pytorch_lightning import seed_everything\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "def train(cfg: Config, fold_num):\n",
    "    seed_everything(Config.seed)\n",
    "    gpus = torch.cuda.device_count()\n",
    "    fd_data_module = FDDataModule(cfg)\n",
    "    fd_data_module.set_fold_num(fold_num)\n",
    "    fd_data_module.setup()\n",
    "    class_weight = fd_data_module.get_class_weight()\n",
    "\n",
    "    if cfg.phase=='test':\n",
    "        fd_module = FDModule(cfg, class_weight=None).load_from_checkpoint(cfg.ckpt,\n",
    "         cfg=Config)\n",
    "    else:\n",
    "        fd_module = FDModule(cfg, class_weight=class_weight)\n",
    "    \n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(monitor='val_loss', save_top_k=5, dirpath=f'results/{cfg.exp}/{fd_data_module.fold_num}',\n",
    "    filename=\"{epoch:02d}-{val_loss:.6f}-{val_acc:.4f}-{val_f1_macro:.6f}.pth\", mode='min')\n",
    "    trainer = pl.Trainer(\n",
    "#         gpus=0,\n",
    "        accelerator='gpu',\n",
    "        num_nodes=1,\n",
    "        deterministic=True,\n",
    "        check_val_every_n_epoch=1,\n",
    "        callbacks = [model_checkpoint],\n",
    "        precision=16,\n",
    "        log_every_n_steps=4,\n",
    "        max_epochs = cfg.max_epochs,\n",
    "#         auto_lr_find=True,\n",
    "#         strategy = DDPStrategy(find_unused_parameters=False),\n",
    "    )\n",
    "    \n",
    "    if cfg.phase == 'train':\n",
    "        trainer.fit(fd_module, fd_data_module)\n",
    "    else:\n",
    "        trainer.test(fd_module, fd_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc897034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: train.csv\n",
      "FOLD NUM:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\envs\\venv\\lib\\site-packages\\lightning_fabric\\connector.py:562: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type                 | Params\n",
      "--------------------------------------------------------\n",
      "0 | model          | FDModel              | 14.8 M\n",
      "1 | val_metric     | MulticlassF1Score    | 0     \n",
      "2 | train_metric   | MulticlassF1Score    | 0     \n",
      "3 | softmax        | Softmax              | 0     \n",
      "4 | horizontalflip | RandomHorizontalFlip | 0     \n",
      "5 | verticalflip   | RandomVerticalFlip   | 0     \n",
      "6 | rotation_left  | RandomRotation       | 0     \n",
      "7 | rotation_right | RandomRotation       | 0     \n",
      "--------------------------------------------------------\n",
      "14.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.8 M    Total params\n",
      "59.099    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD NUM:0\n",
      "optimizer: AdamW\n",
      "scheduler: CosineAnnealing\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03279709815979004,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0611bab994b5464c94161589f3bfca05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4412/1948997939.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'exp_1_1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4412/1577448964.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(cfg, fold_num)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfd_data_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfd_data_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_unwrap_optimized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[0;32m    521\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         )\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    933\u001b[0m         \u001b[1;31m# RUN THE TRAINER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m         \u001b[1;31m# ----------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[1;31m# ----------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m             \u001b[1;31m# run eval step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m             \u001b[0mval_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m             \u001b[0mcall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"on_sanity_check_end\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_last_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mprevious_dataloader_idx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[1;31m# this will run only when no pre-fetching was done.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m                 \u001b[1;31m# consume the batch we just fetched\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py\u001b[0m in \u001b[0;36m_fetch_next_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_profiler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop_profiler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Sequential\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_idx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4412/2512971340.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'uid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \"\"\"\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mF_pil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_pil_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"pic should be PIL Image or ndarray. Got {type(pic)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "Config.exp = 'exp_1_1'\n",
    "train(Config, 0)\n",
    "train(Config, 1)\n",
    "train(Config, 2)\n",
    "train(Config, 3)\n",
    "train(Config, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d6a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.exp = 'exp_1_2'\n",
    "Config.model_name = 'gluon_seresnext101_32x4d'\n",
    "\n",
    "train(Config, 0)\n",
    "train(Config, 1)\n",
    "train(Config, 2)\n",
    "train(Config, 3)\n",
    "train(Config, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1_1_ckpt = []\n",
    "exp_1_2_ckpt = []\n",
    "\n",
    "\n",
    "for f in range(5):\n",
    "    fold_lst = glob(f'results/exp_1_1/{f}/*')\n",
    "    _min = 10000\n",
    "    idx = 0\n",
    "    for i, v in enumerate([float(x.split('val_loss=')[1].split('-')[0]) for x in fold_lst]):\n",
    "        if v < _min:\n",
    "            _min = v\n",
    "            idx = i\n",
    "    exp_1_1_ckpt.append(fold_lst[idx])\n",
    "\n",
    "for f in range(5):\n",
    "    fold_lst = glob(f'results/exp_1_2/{f}/*')\n",
    "    _min = 10000\n",
    "    idx = 0\n",
    "    for i, v in enumerate([float(x.split('val_loss=')[1].split('-')[0]) for x in fold_lst]):\n",
    "        if v < _min:\n",
    "            _min = v\n",
    "            idx = i\n",
    "    exp_1_2_ckpt.append(fold_lst[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02070860",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1_ckpt = []\n",
    "\n",
    "for i, (e_1, e_2) in enumerate(zip(exp_1_1_ckpt, exp_1_2_ckpt)):\n",
    "    ckpt = e_1 if float(e_1.split('val_loss=')[1].split('-')[0]) <= float(e_2.split('val_loss=')[1].split('-')[0]) else e_2\n",
    "    exp_1_ckpt.append(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95228a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1_1_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e22513",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1_2_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1_ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3788fb",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.phase = 'test'\n",
    "\n",
    "def test(cfg: Config):\n",
    "    seed_everything(Config.seed)\n",
    "    fd_data_module = FDDataModule(cfg)\n",
    "    fd_data_module.setup(stage='test')\n",
    "    fd_module = FDModule(cfg, class_weight=None).load_from_checkpoint(cfg.ckpt, cfg=Config)\n",
    "    \n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint(monitor='val_loss', save_top_k=3, dirpath=f'results/{cfg.exp}/{fd_data_module.fold_num}',\n",
    "    filename=\"{epoch:02d}-{val_loss:.6f}-{val_acc:.4f}-{val_f1_macro}.pth\", mode='min')\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "#         gpus=\"0\",\n",
    "        accelerator='gpu',\n",
    "        num_nodes=1,\n",
    "        deterministic=True,\n",
    "        check_val_every_n_epoch=1,\n",
    "        callbacks = [model_checkpoint],\n",
    "        precision=16,\n",
    "        log_every_n_steps=4,\n",
    "        max_epochs = 1,\n",
    "#         auto_lr_find=True,\n",
    "#         strategy = DDPStrategy(find_unused_parameters=False),\n",
    "    )\n",
    "    trainer.test(fd_module, fd_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ckpt in enumerate(exp_1_ckpt):\n",
    "    Config.exp = f'exp_1_fold_{i}'\n",
    "    Config.ckpt = ckpt\n",
    "    Config.model_name = 'gluon_seresnext101_32x4d' if 'exp_1_2' in Config.ckpt else \"seresnext26d_32x4d\"\n",
    "    test(Config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9735a3",
   "metadata": {},
   "source": [
    "## Ensemble, Psuedo Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_0 = pd.read_csv('result_exp_1_fold_0.csv')\n",
    "fold_1 = pd.read_csv('result_exp_1_fold_1.csv')\n",
    "fold_2 = pd.read_csv('result_exp_1_fold_2.csv')\n",
    "fold_3 = pd.read_csv('result_exp_1_fold_3.csv')\n",
    "fold_4 = pd.read_csv('result_exp_1_fold_4.csv')\n",
    "\n",
    "df = pd.concat([fold_0,fold_1,fold_2,fold_3,fold_4])\n",
    "df = df.groupby('uid').mean()\n",
    "df['_max'] = df.max(axis=1)\n",
    "df['label'] = df.idxmax(axis=1).str[-1].astype(int)\n",
    "pseudo_label_df = df[df['_max'] > 0.85][['label']] # 4211 len\n",
    "pseudo_label_df['img_path'] = 'test_imgs/'+pseudo_label_df.index.astype(str)+'.jpg'\n",
    "pseudo_label_df = pseudo_label_df.reset_index()[['uid','img_path','label']]\n",
    "org_train = pd.read_csv('./data/train.csv')\n",
    "\n",
    "full_train_df = pd.concat([org_train[['uid','img_path','label']], pseudo_label_df],axis=0)\n",
    "full_train_df.to_csv('./data/full_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb4a895",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e10d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.exp = 'exp_2_1'\n",
    "Config.model_name = 'gluon_seresnext101_32x4d'\n",
    "Config.phase = 'train'\n",
    "Config.max_epochs=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85629c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(Config, 0)\n",
    "train(Config, 1)\n",
    "train(Config, 2)\n",
    "train(Config, 3)\n",
    "train(Config, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e16aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.exp = 'exp_2_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50928101",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(Config, 0)\n",
    "train(Config, 1)\n",
    "train(Config, 2)\n",
    "train(Config, 3)\n",
    "train(Config, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_2_1_ckpt = []\n",
    "exp_2_2_ckpt = []\n",
    "\n",
    "\n",
    "for f in range(5):\n",
    "    fold_lst = glob(f'results/exp_2_1/{f}/*')\n",
    "    _min = 10000\n",
    "    idx = 0\n",
    "    for i, v in enumerate([float(x.split('val_loss=')[1].split('-')[0]) for x in fold_lst]):\n",
    "        if v < _min:\n",
    "            _min = v\n",
    "            idx = i\n",
    "    exp_2_1_ckpt.append(fold_lst[idx])\n",
    "\n",
    "for f in range(5):\n",
    "    fold_lst = glob(f'results/exp_2_2/{f}/*')\n",
    "    _min = 10000\n",
    "    idx = 0\n",
    "    for i, v in enumerate([float(x.split('val_loss=')[1].split('-')[0]) for x in fold_lst]):\n",
    "        if v < _min:\n",
    "            _min = v\n",
    "            idx = i\n",
    "    exp_2_2_ckpt.append(fold_lst[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11311e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_2_ckpt = []\n",
    "\n",
    "for i,(e_1, e_2) in enumerate(zip(exp_2_1_ckpt, exp_2_2_ckpt)):\n",
    "    ckpt = e_1 if float(e_1.split('val_loss=')[1].split('-')[0]) <= float(e_2.split('val_loss=')[1].split('-')[0]) else e_2\n",
    "    exp_2_ckpt.append(ckpt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ca411",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_2_1_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ad16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_2_2_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_2_ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6362e",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126a691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Config.phase = 'test'\n",
    "\n",
    "for i,ckpt in enumerate(exp_2_ckpt):\n",
    "    Config.exp = f'exp_2_fold_{i}'\n",
    "    Config.ckpt = ckpt\n",
    "    test(Config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414fc10e",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0bd7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_0 = pd.read_csv('result_exp_2_fold_0.csv')\n",
    "fold_1 = pd.read_csv('result_exp_2_fold_1.csv')\n",
    "fold_2 = pd.read_csv('result_exp_2_fold_2.csv')\n",
    "fold_3 = pd.read_csv('result_exp_2_fold_3.csv')\n",
    "fold_4 = pd.read_csv('result_exp_2_fold_4.csv')\n",
    "\n",
    "df = pd.concat([fold_0,fold_1,fold_2,fold_3,fold_4])\n",
    "df = df.groupby('uid').mean()\n",
    "series = df.idxmax(axis=1).str[-1].astype(int)\n",
    "result = pd.DataFrame(series,columns=['label'])\n",
    "result.to_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf572a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('submit.csv').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
